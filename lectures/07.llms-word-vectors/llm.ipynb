{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b146c0ef-83b3-4b16-998e-2fd737869315",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d5f7f-29fa-4602-8381-8dedcf77d7ed",
   "metadata": {},
   "source": [
    "[ollama.com](https://ollama.com)  \n",
    "[ollama Github doc](https://github.com/ollama/ollama)  \n",
    "[ollama Python doc](https://github.com/ollama/ollama-python)  \n",
    "[markdown doc](https://python-markdown.github.io/reference/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12567bf4-2968-40d3-9dcc-b24b879808a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import IPython\n",
    "import markdown\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ollama.com/library/gemma3\n",
    "model_name = \"gemma3:270m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dd7ef-2c79-44a9-ab23-3cb0f50e9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the model is downloaded, if not pull from the server\n",
    "if model_name not in [m.model for m in ollama.list().models]:\n",
    "    ollama.pull(model_name)\n",
    "\n",
    "response: ollama.ChatResponse = ollama.chat(model=model_name, messages=[\n",
    "  { \"role\": \"user\", \"content\": \"Why is the sky blue?\" },\n",
    "])\n",
    "print(response[\"message\"][\"content\"])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e99a67-a7a1-44e7-b0e3-8202368cce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e9c20-783e-4e75-9056-fc1a2702d02c",
   "metadata": {},
   "source": [
    "## Note: handle markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322cbb6-7e7e-422b-973c-404c262c33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md2html(text):\n",
    "    return markdown.markdown(text)\n",
    "\n",
    "def print_html(raw_html):\n",
    "    IPython.display.display_html(raw_html, raw=True)\n",
    "\n",
    "print_html(md2html(response.message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5096635-de00-4e34-922f-d3f51e0335c6",
   "metadata": {},
   "source": [
    "## Gradual printing / streaming responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a32f49-5e20-4aa3-8474-b9bae9e5e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = ollama.chat(\n",
    "    model=model_name,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Why is the sky blue?\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk[\"message\"][\"content\"], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04775a-5f39-4664-b239-b37ff24ecfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = ollama.chat(\n",
    "    model=model_name,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Why is the sky blue?\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "import time\n",
    "\n",
    "text = \"\"\n",
    "for chunk in stream:\n",
    "    text += chunk[\"message\"][\"content\"]\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    print_html(md2html(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5b033-1ef8-4643-a726-07d7551eafe3",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc723c1-ed11-4d53-870d-9d09d6ff4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ollama.com/library/all-minilm\n",
    "embed_model_name = \"all-minilm\"\n",
    "\n",
    "# test if the model is downloaded, if not pull from the server\n",
    "if embed_model_name not in [m.model for m in ollama.list().models]:\n",
    "    ollama.pull(embed_model_name)\n",
    "    \n",
    "response: ollama.EmbedResponse = ollama.embed(\n",
    "    model=embed_model_name,\n",
    "    input=[\"Why is the sky blue?\"], # can be a single string, or a list of strings\n",
    ")\n",
    "\n",
    "# or access fields directly from the response object\n",
    "print(response.embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46f2ef-5506-43e5-bc9e-daa486db2948",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff461923-d971-4672-bfd4-ed27b131d725",
   "metadata": {},
   "source": [
    "[wiki](https://en.wikipedia.org/wiki/Cosine_similarity#Definition)  \n",
    "\n",
    "Exquation: $\\frac{A \\cdot B}{||A||||B||}$.\n",
    "\n",
    "**Note**:  \n",
    "You can also find it implemented in `scikit-learn`, you can add it with `uv` and then import it:\n",
    "```python\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb00e0-805e-400c-ac85-3fcdf5f6c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    See here: https://gist.github.com/robert-mcdermott/5957ef1ddcfc7c3ba898d800531b2aa7\n",
    "    \"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    cosine_similarity = dot_product / (norm1 * norm2)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4938b-1349-45ed-b040-bb68d03e2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Why is the sky blue?\",\n",
    "    \"Why is the sky orange?\",\n",
    "    \"Tonight I'll be eating soup\"\n",
    "]\n",
    "\n",
    "response: ollama.EmbedResponse = ollama.embed(\n",
    "    model=embed_model_name,\n",
    "    input=sentences,\n",
    ")\n",
    "\n",
    "# or access fields directly from the response object\n",
    "print(len(response.embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cacd9-6f52-4261-845e-c5974f16b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_similarities(s1_id, s2_id, embeddings):\n",
    "    print(f\"Similarity between:\")\n",
    "    print(f\" - '{sentences[s1_id]}'\")\n",
    "    print(f\" - '{sentences[s2_id]}'\")\n",
    "    print(f\"   => {cosine_similarity(embeddings[s1_id], embeddings[s2_id])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593a8d6-a94a-4cee-8a7a-0c616cf766d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_similarities(0, 1, response.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39134817-a244-4369-95b3-2fe79ba3f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_similarities(0, 2, response.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bc3d7-eea5-4cb0-834c-0e82e16b6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_similarities(1, 2, response.embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetic.machines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
